{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef2fa2d",
   "metadata": {},
   "source": [
    "## **TF-IDF** : Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ceb39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b68cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countVectorizer = CountVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e9d571",
   "metadata": {},
   "source": [
    "### 1. Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6536d63",
   "metadata": {},
   "source": [
    "Term Frequency is the number of occurences of a term (e.g. a word) in a text sample, but normalized by the numbers of words in that sample. \n",
    "\n",
    "It is very close to a Bag Of Words (BOW) : the main difference is the normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29f9cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote0 = \"Love yourself first and everything else falls into line. You really have to love yourself to get anything done in this world.\"\n",
    "quote1 = \"Love is a really serious mental disease.\"\n",
    "quote2 = \"Better to love and lose, than to never love at all.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f66d58",
   "metadata": {},
   "source": [
    "### We are looking for the query \"love\", and we want to find the most relevant quote among 3 different quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2167ca81",
   "metadata": {},
   "source": [
    "### compute the BOW of each quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a9766d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW = countVectorizer.fit_transform([quote0, quote1, quote2]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d4ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = pd.DataFrame(data=BOW, columns=countVectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "258d08da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>better</th>\n",
       "      <th>disease</th>\n",
       "      <th>falls</th>\n",
       "      <th>line</th>\n",
       "      <th>lose</th>\n",
       "      <th>love</th>\n",
       "      <th>mental</th>\n",
       "      <th>really</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   better  disease  falls  line  lose  love  mental  really  world\n",
       "0       0        0      1     1     0     2       0       1      1\n",
       "1       0        1      0     0     0     1       1       1      0\n",
       "2       1        0      0     0     1     2       0       0      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84170e16",
   "metadata": {},
   "source": [
    "from this BOW, the most relevant quotes would be the quotes 0 and 2: because there are 2 occurencies of \"love\"; and only one in the quote 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd3783c",
   "metadata": {},
   "source": [
    "### Impact of normalizing every value by the number of words in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4afd922e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    4\n",
       "2    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4044672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>better</th>\n",
       "      <th>disease</th>\n",
       "      <th>falls</th>\n",
       "      <th>line</th>\n",
       "      <th>lose</th>\n",
       "      <th>love</th>\n",
       "      <th>mental</th>\n",
       "      <th>really</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   better  disease     falls      line  lose      love  mental    really  \\\n",
       "0    0.00     0.00  0.166667  0.166667  0.00  0.333333    0.00  0.166667   \n",
       "1    0.00     0.25  0.000000  0.000000  0.00  0.250000    0.25  0.250000   \n",
       "2    0.25     0.00  0.000000  0.000000  0.25  0.500000    0.00  0.000000   \n",
       "\n",
       "      world  \n",
       "0  0.166667  \n",
       "1  0.000000  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = bow.divide(bow.sum(axis=1), axis=0)\n",
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1652935",
   "metadata": {},
   "source": [
    "Term Frequency : the quote 2 is the most relevant compared to quotes 0 and 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0530af1f",
   "metadata": {},
   "source": [
    "### 2. Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f860ac",
   "metadata": {},
   "source": [
    "**IDF** : represents the inverse of the frequency that a term appears in our documents. \n",
    "\n",
    "So basically, the IDF will give a **higher weight** to the words that occur rarely in our documents, and **reduce the weight** of words that occur frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7d1a5",
   "metadata": {},
   "source": [
    "üëâüèª Let's calculate the **IDF** for a few words using our example of quotes.\n",
    "\n",
    "We have 3 documents, so: **D = 3**\n",
    "Word: `love`\n",
    "- Appears in **3 documents**\n",
    "- üßÆ IDF love = log(3 / 3) = **0**\n",
    "\n",
    "Word: `really`\n",
    "- Appears in **2 documents**\n",
    "- üßÆ IDF really = log(3 / 2) ‚âà **0.4**\n",
    "\n",
    "Word: `disease`\n",
    "- Appears in **1 document**\n",
    "- üßÆ IDF disease = log(3 / 1) ‚âà **1.1**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edf3848b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>better</th>\n",
       "      <th>disease</th>\n",
       "      <th>falls</th>\n",
       "      <th>line</th>\n",
       "      <th>lose</th>\n",
       "      <th>love</th>\n",
       "      <th>mental</th>\n",
       "      <th>really</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   better  disease  falls  line  lose  love  mental  really  world\n",
       "0       0        0      1     1     0     1       0       1      1\n",
       "1       0        1      0     0     0     1       1       1      0\n",
       "2       1        0      0     0     1     1       0       0      0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is the token present or not at least once in the document ? \n",
    "is_token_present = (bow > 0).astype(int)\n",
    "is_token_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_token_present = (bow > 0).astype(int)\n",
    "idf = np.log(len(is_token_present) / is_token_present.sum(axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c846d35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbr total of token occurence across all documents\n",
    "idf = np.log(len(is_token_present) / is_token_present.sum(axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4950201e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>better</th>\n",
       "      <th>disease</th>\n",
       "      <th>falls</th>\n",
       "      <th>line</th>\n",
       "      <th>lose</th>\n",
       "      <th>love</th>\n",
       "      <th>mental</th>\n",
       "      <th>really</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     better   disease     falls      line      lose  love    mental    really  \\\n",
       "0  1.098612  1.098612  1.098612  1.098612  1.098612   0.0  1.098612  0.405465   \n",
       "\n",
       "      world  \n",
       "0  1.098612  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf = pd.DataFrame([idf])\n",
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2df610",
   "metadata": {},
   "source": [
    "IDF gives higher weights to words that occur more rarely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f3f266",
   "metadata": {},
   "source": [
    "## **TF-IDF** SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e56b6dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>better</th>\n",
       "      <th>disease</th>\n",
       "      <th>falls</th>\n",
       "      <th>line</th>\n",
       "      <th>lose</th>\n",
       "      <th>love</th>\n",
       "      <th>mental</th>\n",
       "      <th>really</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214614</td>\n",
       "      <td>0.282191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.423287</td>\n",
       "      <td>0.321921</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.423287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423287</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     better   disease     falls      line      lose      love    mental  \\\n",
       "0  0.000000  0.000000  0.282191  0.282191  0.000000  0.333333  0.000000   \n",
       "1  0.000000  0.423287  0.000000  0.000000  0.000000  0.250000  0.423287   \n",
       "2  0.423287  0.000000  0.000000  0.000000  0.423287  0.500000  0.000000   \n",
       "\n",
       "     really     world  \n",
       "0  0.214614  0.282191  \n",
       "1  0.321921  0.000000  \n",
       "2  0.000000  0.000000  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ = tf * ( np.log((1 + len(is_token_present)) / (1 + is_token_present.sum(axis=0))) + 1)\n",
    "tfidf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "32d6a2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>better</th>\n",
       "      <th>disease</th>\n",
       "      <th>falls</th>\n",
       "      <th>line</th>\n",
       "      <th>lose</th>\n",
       "      <th>love</th>\n",
       "      <th>mental</th>\n",
       "      <th>really</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448394</td>\n",
       "      <td>0.448394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341015</td>\n",
       "      <td>0.448394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345205</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.444514</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.542701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542701</td>\n",
       "      <td>0.641055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     better   disease     falls      line      lose      love    mental  \\\n",
       "0  0.000000  0.000000  0.448394  0.448394  0.000000  0.529657  0.000000   \n",
       "1  0.000000  0.584483  0.000000  0.000000  0.000000  0.345205  0.584483   \n",
       "2  0.542701  0.000000  0.000000  0.000000  0.542701  0.641055  0.000000   \n",
       "\n",
       "     really     world  \n",
       "0  0.341015  0.448394  \n",
       "1  0.444514  0.000000  \n",
       "2  0.000000  0.000000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_norms = np.linalg.norm(tfidf_, axis=1, keepdims=True)\n",
    "tfidf_normalized = tfidf_ / l2_norms\n",
    "tfidf_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b445d",
   "metadata": {},
   "source": [
    "**TF-IDF** = TF * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15929ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf = tfidfVectorizer.fit_transform([quote0, quote1, quote2]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5875ddf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.44839402, 0.44839402, 0.        ,\n",
       "        0.52965746, 0.        , 0.34101521, 0.44839402],\n",
       "       [0.        , 0.5844829 , 0.        , 0.        , 0.        ,\n",
       "        0.34520502, 0.5844829 , 0.44451431, 0.        ],\n",
       "       [0.54270061, 0.        , 0.        , 0.        , 0.54270061,\n",
       "        0.64105545, 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f58ba5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>better</th>\n",
       "      <th>disease</th>\n",
       "      <th>falls</th>\n",
       "      <th>line</th>\n",
       "      <th>lose</th>\n",
       "      <th>love</th>\n",
       "      <th>mental</th>\n",
       "      <th>really</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448394</td>\n",
       "      <td>0.448394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341015</td>\n",
       "      <td>0.448394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345205</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.444514</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.542701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542701</td>\n",
       "      <td>0.641055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     better   disease     falls      line      lose      love    mental  \\\n",
       "0  0.000000  0.000000  0.448394  0.448394  0.000000  0.529657  0.000000   \n",
       "1  0.000000  0.584483  0.000000  0.000000  0.000000  0.345205  0.584483   \n",
       "2  0.542701  0.000000  0.000000  0.000000  0.542701  0.641055  0.000000   \n",
       "\n",
       "     really     world  \n",
       "0  0.341015  0.448394  \n",
       "1  0.444514  0.000000  \n",
       "2  0.000000  0.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf, columns=tfidfVectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e10aea",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cc41cb",
   "metadata": {},
   "source": [
    "### 1. Jaccard Similarity\n",
    "\n",
    "Jaccard Similarity is a very simple metric to measure similarity: \n",
    "- the size of the intersection divided by the size of the union of the sample sets. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "175fc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'Robots and humans are friends'\n",
    "B = 'Mark and Elon are not friends'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "413e3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_A = set(A.split())\n",
    "token_B = set(B.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b8cbaf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter = token_A.intersection(token_B)\n",
    "uni = token_A.union(token_B)\n",
    "jaccard_s = len(inter) / len(uni)\n",
    "jaccard_s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1772aff",
   "metadata": {},
   "source": [
    "### 2. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6411b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1.2, 0.5, -0.1, 0.8])\n",
    "Y = np.array([-0.3, 1.1, 0.5, 0.4])\n",
    "Z = np.array([1.3, 0.4, 0, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "019cf768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "301e6474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.22995976],\n",
       "       [0.22995976, 1.        ]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_x_y = cosine_similarity([X, Y])\n",
    "cos_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "901683ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99426841],\n",
       "       [0.99426841, 1.        ]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_x_z = cosine_similarity([X, Z])\n",
    "cos_x_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1748b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.17930979],\n",
       "       [0.17930979, 1.        ]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_y_z = cosine_similarity([Y, Z])\n",
    "cos_y_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe735c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elon</th>\n",
       "      <th>friends</th>\n",
       "      <th>humans</th>\n",
       "      <th>mark</th>\n",
       "      <th>robots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449436</td>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.449436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       elon   friends    humans      mark    robots\n",
       "0  0.000000  0.449436  0.631667  0.000000  0.631667\n",
       "1  0.631667  0.449436  0.000000  0.631667  0.000000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TD-IFD\n",
    "tfidf_A_B = tfidfVectorizer.fit_transform([A, B]).toarray()\n",
    "pd.DataFrame(data=tfidf_A_B, columns=tfidfVectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cf4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.20199309],\n",
       "       [0.20199309, 1.        ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without stopwords\n",
    "cosine_similarity(tfidf_A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "192da84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.38087261],\n",
       "       [0.38087261, 1.        ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with stopwords\n",
    "tfidfVectorizer = TfidfVectorizer()\n",
    "tfidf_A_B = tfidfVectorizer.fit_transform([A, B]).toarray()\n",
    "pd.DataFrame(data=tfidf_A_B, columns=tfidfVectorizer.get_feature_names_out())\n",
    "cosine_similarity(tfidf_A_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a800f",
   "metadata": {},
   "source": [
    "## Chatbot : rule based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ce646e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "greetings_inputs = ['Hello', 'Hi', 'Good morning', 'Hey']\n",
    "greetings_answers = ['Hey there, I am Siri, how can I help you?', 'Hello, my name is Siri, nice to meet you.',\n",
    "                     'Siri at your service, sir.', 'Hi Master, I am Siri.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1af06d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Siri, nice to meet you.\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter your question ?\")\n",
    "if query in greetings_inputs:\n",
    "    output = np.random.choice(greetings_answers)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f20a1d",
   "metadata": {},
   "source": [
    "## Chatbot : self learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa45cc",
   "metadata": {},
   "source": [
    "Retrieval based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "42426721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database\n",
    "database = \"\"\"A chatbot (also known as a smartbot, talkbot, chatterbot, Bot, IM bot, interactive agent, \n",
    "conversational interface or artificial conversational entity) is a computer program or an \n",
    "artificial intelligence which conducts a conversation via auditory or textual methods. \n",
    "Such programs are often designed to convincingly simulate how a human would behave as a \n",
    "conversational partner, thereby passing the Turing test. Chatbots are typically used in \n",
    "dialog systems for various practical purposes including customer service or information \n",
    "acquisition. Some chatbots use sophisticated natural language processing systems, but many \n",
    "simpler ones scan for keywords within the input, then pull a reply with the most matching \n",
    "keywords, or the most similar wording pattern, from a database.\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ea4369d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5db2c3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A chatbot (also known as a smartbot, talkbot, chatterbot, Bot, IM bot, interactive agent, \\nconversational interface or artificial conversational entity) is a computer program or an \\nartificial intelligence which conducts a conversation via auditory or textual methods.',\n",
       " 'Such programs are often designed to convincingly simulate how a human would behave as a \\nconversational partner, thereby passing the Turing test.',\n",
       " 'Chatbots are typically used in \\ndialog systems for various practical purposes including customer service or information \\nacquisition.',\n",
       " 'Some chatbots use sophisticated natural language processing systems, but many \\nsimpler ones scan for keywords within the input, then pull a reply with the most matching \\nkeywords, or the most similar wording pattern, from a database.']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_db = sent_tokenize(database)\n",
    "token_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "24f8bdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acquisition</th>\n",
       "      <th>agent</th>\n",
       "      <th>artificial</th>\n",
       "      <th>auditory</th>\n",
       "      <th>behave</th>\n",
       "      <th>bot</th>\n",
       "      <th>chatbot</th>\n",
       "      <th>chatbots</th>\n",
       "      <th>chatterbot</th>\n",
       "      <th>computer</th>\n",
       "      <th>...</th>\n",
       "      <th>systems</th>\n",
       "      <th>talkbot</th>\n",
       "      <th>test</th>\n",
       "      <th>textual</th>\n",
       "      <th>turing</th>\n",
       "      <th>typically</th>\n",
       "      <th>use</th>\n",
       "      <th>used</th>\n",
       "      <th>various</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187362</td>\n",
       "      <td>0.374724</td>\n",
       "      <td>0.187362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374724</td>\n",
       "      <td>0.187362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187362</td>\n",
       "      <td>0.187362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.285794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285794</td>\n",
       "      <td>0.285794</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acquisition     agent  artificial  auditory    behave       bot   chatbot  \\\n",
       "0     0.000000  0.187362    0.374724  0.187362  0.000000  0.374724  0.187362   \n",
       "1     0.000000  0.000000    0.000000  0.000000  0.306835  0.000000  0.000000   \n",
       "2     0.285794  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "   chatbots  chatterbot  computer  ...   systems   talkbot      test  \\\n",
       "0  0.000000    0.187362  0.187362  ...  0.000000  0.187362  0.000000   \n",
       "1  0.000000    0.000000  0.000000  ...  0.000000  0.000000  0.306835   \n",
       "2  0.225323    0.000000  0.000000  ...  0.225323  0.000000  0.000000   \n",
       "3  0.171058    0.000000  0.000000  ...  0.171058  0.000000  0.000000   \n",
       "\n",
       "    textual    turing  typically       use      used   various   wording  \n",
       "0  0.187362  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.306835   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000   0.285794  0.000000  0.285794  0.285794  0.000000  \n",
       "3  0.000000  0.000000   0.000000  0.216965  0.000000  0.000000  0.216965  \n",
       "\n",
       "[4 rows x 61 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TDIDF of database\n",
    "tfidfVectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "tfidf_db = tfidfVectorizer.fit_transform(token_db).toarray()\n",
    "pd.DataFrame(data=tfidf_db, columns=tfidfVectorizer.get_feature_names_out())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0a70f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity():\n",
    "    # get user input\n",
    "    query = input(\"What is your question ?\").strip()\n",
    "    print(f\"Query : {query}\")\n",
    "    \n",
    "    # vectorize the user input to a tfidf using same param as db\n",
    "    tfidf_query = tfidfVectorizer.transform([query]).toarray()\n",
    "    \n",
    "    # search for similarity between user query and db\n",
    "    cosine_s = cosine_similarity(tfidf_query, tfidf_db)\n",
    "    \n",
    "    return cosine_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "83130649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : Where is London?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f54b0",
   "metadata": {},
   "source": [
    "No similarity with all 4 token in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1e24ebb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : What is a chatbot?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.18736197, 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score = get_similarity()\n",
    "similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5968d38",
   "metadata": {},
   "source": [
    "Some similarity with the first token in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "53c4d30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A chatbot (also known as a smartbot, talkbot, chatterbot, Bot, IM bot, interactive agent, \n",
      "conversational interface or artificial conversational entity) is a computer program or an \n",
      "artificial intelligence which conducts a conversation via auditory or textual methods.\n"
     ]
    }
   ],
   "source": [
    "# retrival of answer\n",
    "print(token_db[similarity_score.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d1540a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : What are chatbot used for ?\n",
      "\n",
      "Answer : \n",
      "Chatbots are typically used in \n",
      "dialog systems for various practical purposes including customer service or information \n",
      "acquisition.\n"
     ]
    }
   ],
   "source": [
    "similarity_score = get_similarity()\n",
    "similarity_score\n",
    "# retrival of answer\n",
    "print()\n",
    "print(f\"Answer : \\n{token_db[similarity_score.argmax()]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
